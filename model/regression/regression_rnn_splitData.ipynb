{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.19"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "data_index = 2\n",
    "dataset_path = f\"../../dataset/dataset_0725/p{data_index}\"\n",
    "os.makedirs(dataset_path, exist_ok=True)\n",
    "saveModel_dir = f'../../savedModel/p{data_index}'\n",
    "results_dir = f'../../saveResult/p{data_index}'\n",
    "\n",
    "saveplot_dir = f'../../savePlot/p{data_index}'\n",
    "os.makedirs(saveplot_dir, exist_ok=True)\n",
    "\n",
    "X_train = np.load(f'{dataset_path}/X_train.npy')\n",
    "y_train = np.load(f'{dataset_path}/y_train.npy').astype(float).flatten()\n",
    "X_val = np.load(f'{dataset_path}/X_val.npy')\n",
    "y_val = np.load(f'{dataset_path}/y_val.npy').astype(float).flatten()\n",
    "X_test = np.load(f'{dataset_path}/X_test.npy')\n",
    "y_test = np.load(f'{dataset_path}/y_test.npy').astype(float).flatten()\n",
    "\n",
    "\n",
    "max(y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with lr list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 假设 X_train, y_train, X_val, y_val, X_test, y_test 数据已经存在\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# 将数据转换为 PyTorch 张量\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# 数据归一化\n",
    "mean = X_train_tensor.mean(dim=0, keepdim=True)\n",
    "std = X_train_tensor.std(dim=0, keepdim=True)\n",
    "X_train_tensor = (X_train_tensor - mean) / std\n",
    "X_val_tensor = (X_val_tensor - mean) / std\n",
    "X_test_tensor = (X_test_tensor - mean) / std\n",
    "\n",
    "# 创建数据加载器\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 定义 RNN 回归模型\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# 定义自定义的准确率函数\n",
    "def calculate_custom_accuracy(predictions, targets, tolerance=0.1):\n",
    "    predictions = predictions.detach().cpu().numpy()\n",
    "    targets = targets.detach().cpu().numpy()\n",
    "    correct = np.abs(predictions - targets) < tolerance\n",
    "    accuracy = np.mean(correct)\n",
    "    return accuracy\n",
    "\n",
    "# learning_rates = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6]\n",
    "learning_rates = [ 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "num_epochs = 1000\n",
    "\n",
    "results = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with learning rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning Rate 0.01:   0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning Rate 0.01:   5%|▍         | 49/1000 [00:19<06:18,  2.52it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 49\u001b[0m\n\u001b[1;32m     47\u001b[0m all_predictions_train \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     48\u001b[0m all_labels_train \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     50\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     52\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# 调整维度为 (batch_size, seq_length, input_dim)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:277\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    217\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:144\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    141\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtransposed\u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:144\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    141\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:121\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 121\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:174\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    172\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    173\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[0;32m--> 174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 定义保存模型的目录\n",
    "\n",
    "\n",
    "\n",
    "# 定义保存模型的函数\n",
    "def save_checkpoint(model, optimizer, epoch, val_accuracy, val_loss, file_path):\n",
    "    \n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'val_accuracy': val_accuracy,\n",
    "        'val_loss': val_loss\n",
    "    }\n",
    "    torch.save(checkpoint, file_path)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for lr in learning_rates:\n",
    "    print(f\"Training with learning rate: {lr}\")\n",
    "    model = RNNModel(input_dim=12, hidden_dim=128, output_dim=1, num_layers=2).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    best_val_accuracy = 0.0\n",
    "    best_val_accuracy_epoch = 0\n",
    "    lowest_val_loss = float('inf')\n",
    "    lowest_val_loss_epoch = 0\n",
    "    best_train_accuracy = 0.0\n",
    "    best_train_accuracy_epoch = 0\n",
    "    lowest_train_loss = float('inf')\n",
    "    lowest_train_loss_epoch = 0\n",
    "    train_output_result = []\n",
    "    train_true_result = []\n",
    "    val_output_result = []\n",
    "    val_true_result = []\n",
    "    for epoch in tqdm(range(num_epochs), desc=f\"Learning Rate {lr}\"):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        all_predictions_train = []\n",
    "        all_labels_train = []\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            inputs = inputs.unsqueeze(1)  # 调整维度为 (batch_size, seq_length, input_dim)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            loss = criterion(outputs, labels.unsqueeze(1))  # 将标签调整为 (batch_size, 1)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            all_predictions_train.append(outputs)\n",
    "            all_labels_train.append(labels.unsqueeze(1))\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        train_losses.append(epoch_loss)\n",
    "        \n",
    "        all_predictions_train = torch.cat(all_predictions_train, dim=0)\n",
    "        all_labels_train = torch.cat(all_labels_train, dim=0)\n",
    "\n",
    "        train_output_result.append(all_predictions_train)\n",
    "        train_true_result.append(all_labels_train)\n",
    "\n",
    "        train_accuracy = calculate_custom_accuracy(all_predictions_train, all_labels_train, tolerance=0.5)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_accuracy = 0.0\n",
    "        all_predictions = []\n",
    "        all_labels = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                inputs = inputs.unsqueeze(1)  # 调整维度为 (batch_size, seq_length, input_dim)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels.unsqueeze(1))  # 将标签调整为 (batch_size, 1)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                \n",
    "                all_predictions.append(outputs)\n",
    "                all_labels.append(labels.unsqueeze(1))\n",
    "        \n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        all_predictions = torch.cat(all_predictions, dim=0)\n",
    "        all_labels = torch.cat(all_labels, dim=0)\n",
    "\n",
    "        val_output_result.append(all_predictions)\n",
    "        val_true_result.append(all_labels)\n",
    "\n",
    "        val_accuracy = calculate_custom_accuracy(all_predictions, all_labels, tolerance=0.5)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        \n",
    "        # 记录最好的准确率和最低的损失\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_val_accuracy_epoch = epoch + 1\n",
    "            # 保存模型\n",
    "            save_checkpoint(model, optimizer, epoch + 1, val_accuracy, val_loss, os.path.join(saveModel_dir, f\"best_val_accuracy_lr_{lr}.pt\"))\n",
    "        \n",
    "        if val_loss < lowest_val_loss:\n",
    "            lowest_val_loss = val_loss\n",
    "            lowest_val_loss_epoch = epoch + 1\n",
    "            # 保存模型\n",
    "            save_checkpoint(model, optimizer, epoch + 1, val_accuracy, val_loss, os.path.join(saveModel_dir, f\"lowest_val_loss_lr_{lr}.pt\"))\n",
    "        \n",
    "        if train_accuracy > best_train_accuracy:\n",
    "            best_train_accuracy = train_accuracy\n",
    "            best_train_accuracy_epoch = epoch + 1\n",
    "            # 保存模型\n",
    "            save_checkpoint(model, optimizer, epoch + 1, train_accuracy, epoch_loss, os.path.join(saveModel_dir, f\"best_train_accuracy_lr_{lr}.pt\"))\n",
    "        \n",
    "        if epoch_loss < lowest_train_loss:\n",
    "            lowest_train_loss = epoch_loss\n",
    "            lowest_train_loss_epoch = epoch + 1\n",
    "            # 保存模型\n",
    "            save_checkpoint(model, optimizer, epoch + 1, train_accuracy, epoch_loss, os.path.join(saveModel_dir, f\"lowest_train_loss_lr_{lr}.pt\"))\n",
    "\n",
    "    results[lr] = {\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'train_accuracies': train_accuracies,\n",
    "        'val_accuracies': val_accuracies,\n",
    "        'best_val_accuracy': best_val_accuracy,\n",
    "        'best_val_accuracy_epoch': best_val_accuracy_epoch,\n",
    "        'lowest_val_loss': lowest_val_loss,\n",
    "        'lowest_val_loss_epoch': lowest_val_loss_epoch,\n",
    "        'best_train_accuracy': best_train_accuracy,\n",
    "        'best_train_accuracy_epoch': best_train_accuracy_epoch,\n",
    "        'lowest_train_loss': lowest_train_loss,\n",
    "        'lowest_train_loss_epoch': lowest_train_loss_epoch,\n",
    "        'train_output_result': train_output_result,\n",
    "        'train_true_result': train_true_result,\n",
    "        'val_output_result': val_output_result,\n",
    "        'val_true_result': val_true_result\n",
    "    }\n",
    "\n",
    "    import os\n",
    "\n",
    "# 创建保存图片的目录\n",
    "\n",
    "\n",
    "# 绘制图表\n",
    "for lr, result in results.items():\n",
    "    epochs = range(1, num_epochs + 1)\n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, result['train_losses'], 'bo-', label='Training loss')\n",
    "    plt.plot(epochs, result['val_losses'], 'b-', label='Validation loss')\n",
    "    plt.title(f'Training and validation loss (lr={lr})')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, result['train_accuracies'], 'bo-', label='Training accuracy')\n",
    "    plt.plot(epochs, result['val_accuracies'], 'b-', label='Validation accuracy')\n",
    "    plt.title(f'Training and validation accuracy (lr={lr})')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 保存图片\n",
    "    plot_filename = os.path.join(saveplot_dir, f'training_validation_lr_{lr}.png')\n",
    "    plt.savefig(plot_filename)\n",
    "    \n",
    "    # 显示图片\n",
    "    plt.show()\n",
    "# 定义保存文件的路径\n",
    "results_file = 'training_results.txt'\n",
    "\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "# 打开文件写入模式\n",
    "with open(f'{results_dir}/{results_file}', 'w') as f:\n",
    "    for lr, result in results.items():\n",
    "        f.write(f\"Learning rate: {lr}\\n\")\n",
    "        f.write(f\"Best Validation Accuracy: {result['best_val_accuracy']:.4f} at epoch {result['best_val_accuracy_epoch']}\\n\")\n",
    "        f.write(f\"Lowest Validation Loss: {result['lowest_val_loss']:.4f} at epoch {result['lowest_val_loss_epoch']}\\n\")\n",
    "        f.write(f\"Best Training Accuracy: {result['best_train_accuracy']:.4f} at epoch {result['best_train_accuracy_epoch']}\\n\")\n",
    "        f.write(f\"Lowest Training Loss: {result['lowest_train_loss']:.4f} at epoch {result['lowest_train_loss_epoch']}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "print(f\"Results saved to {results_dir}/{results_file}\")\n",
    "\n",
    "for lr, result in results.items():\n",
    "    print(f\"Learning rate: {lr}\")\n",
    "    print(f\"Best Validation Accuracy: {result['best_val_accuracy']:.4f} at epoch {result['best_val_accuracy_epoch']}\")\n",
    "    print(f\"Lowest Validation Loss: {result['lowest_val_loss']:.4f} at epoch {result['lowest_val_loss_epoch']}\")\n",
    "    print(f\"Best Training Accuracy: {result['best_train_accuracy']:.4f} at epoch {result['best_train_accuracy_epoch']}\")\n",
    "    print(f\"Lowest Training Loss: {result['lowest_train_loss']:.4f} at epoch {result['lowest_train_loss_epoch']}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# only 1 lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2000], Loss: 29.4857, Training Accuracy: 0.1811\n",
      "Validation Loss: 16.7996, Custom Accuracy: 0.0096\n",
      "Epoch [2/2000], Loss: 8.4995, Training Accuracy: 0.2543\n",
      "Validation Loss: 3.4289, Custom Accuracy: 0.0467\n",
      "Epoch [3/2000], Loss: 3.4464, Training Accuracy: 0.4023\n",
      "Validation Loss: 2.8968, Custom Accuracy: 0.0495\n",
      "Epoch [4/2000], Loss: 3.1495, Training Accuracy: 0.4145\n",
      "Validation Loss: 2.6995, Custom Accuracy: 0.0508\n",
      "Epoch [5/2000], Loss: 2.9695, Training Accuracy: 0.4297\n",
      "Validation Loss: 2.5540, Custom Accuracy: 0.0453\n",
      "Epoch [6/2000], Loss: 2.8115, Training Accuracy: 0.4405\n",
      "Validation Loss: 2.4360, Custom Accuracy: 0.0618\n",
      "Epoch [7/2000], Loss: 2.6844, Training Accuracy: 0.4537\n",
      "Validation Loss: 2.3446, Custom Accuracy: 0.0577\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 108\u001b[0m\n\u001b[1;32m    106\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# 将标签调整为 (batch_size, 1)\u001b[39;00m\n\u001b[1;32m    107\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m--> 108\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    112\u001b[0m all_predictions_train\u001b[38;5;241m.\u001b[39mappend(outputs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/optim/optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m             )\n\u001b[0;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/optim/adam.py:166\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    155\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    157\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    158\u001b[0m         group,\n\u001b[1;32m    159\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    163\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    164\u001b[0m         state_steps)\n\u001b[0;32m--> 166\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/optim/adam.py:316\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    314\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 316\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/optim/adam.py:439\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    437\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m         denom \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[1;32m    443\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# 假设 X_train, y_train, X_val, y_val, X_test, y_test 数据已经存在\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "lr_list = []\n",
    "# 将数据转换为 PyTorch 张量\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# 数据归一化\n",
    "mean = X_train_tensor.mean(dim=0, keepdim=True)\n",
    "std = X_train_tensor.std(dim=0, keepdim=True)\n",
    "X_train_tensor = (X_train_tensor - mean) / std\n",
    "X_val_tensor = (X_val_tensor - mean) / std\n",
    "X_test_tensor = (X_test_tensor - mean) / std\n",
    "\n",
    "# 创建数据加载器\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 定义 RNN 回归模型\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "input_dim = 12\n",
    "hidden_dim = 128\n",
    "output_dim = 1  \n",
    "num_layers = 2\n",
    "\n",
    "model = RNNModel(input_dim, hidden_dim, output_dim, num_layers)\n",
    "\n",
    "# 损失函数和优化器\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)#0.001\n",
    "\n",
    "# 记录损失和评价指标\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "best_val_accuracy = 0.0\n",
    "best_val_accuracy_epoch = 0\n",
    "lowest_val_loss = float('inf')\n",
    "lowest_val_loss_epoch = 0\n",
    "best_train_accuracy = 0.0\n",
    "best_train_accuracy_epoch = 0\n",
    "lowest_train_loss = float('inf')\n",
    "lowest_train_loss_epoch = 0\n",
    "\n",
    "# 训练模型\n",
    "num_epochs = 2000\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# 定义自定义的准确率函数\n",
    "def calculate_custom_accuracy(predictions, targets, tolerance=0.1):\n",
    "    predictions = predictions.detach().cpu().numpy()\n",
    "    targets = targets.detach().cpu().numpy()\n",
    "    correct = np.abs(predictions - targets) < tolerance\n",
    "    accuracy = np.mean(correct)\n",
    "    return accuracy\n",
    "output_result_backup = []\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    all_predictions_train = []\n",
    "    all_labels_train = []\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        inputs = inputs.unsqueeze(1)  # 调整维度为 (batch_size, seq_length, input_dim)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels.unsqueeze(1))  # 将标签调整为 (batch_size, 1)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        all_predictions_train.append(outputs)\n",
    "        all_labels_train.append(labels.unsqueeze(1))\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    train_losses.append(epoch_loss)\n",
    "    \n",
    "    all_predictions_train = torch.cat(all_predictions_train, dim=0)\n",
    "    all_labels_train = torch.cat(all_labels_train, dim=0)\n",
    "    train_accuracy = calculate_custom_accuracy(all_predictions_train, all_labels_train, tolerance=1)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Training Accuracy: {train_accuracy:.4f}')\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_accuracy = 0.0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            inputs = inputs.unsqueeze(1)  # 调整维度为 (batch_size, seq_length, input_dim)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            output_result_backup.append(outputs)\n",
    "            loss = criterion(outputs, labels.unsqueeze(1))  # 将标签调整为 (batch_size, 1)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            all_predictions.append(outputs)\n",
    "            all_labels.append(labels.unsqueeze(1))\n",
    "    \n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    all_predictions = torch.cat(all_predictions, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    val_accuracy = calculate_custom_accuracy(all_predictions, all_labels, tolerance=0.1)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    \n",
    "    print(f'Validation Loss: {val_loss:.4f}, Custom Accuracy: {val_accuracy:.4f}')\n",
    "    \n",
    "    # 记录最好的准确率和最低的损失\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        best_val_accuracy_epoch = epoch + 1\n",
    "    if val_loss < lowest_val_loss:\n",
    "        lowest_val_loss = val_loss\n",
    "        lowest_val_loss_epoch = epoch + 1\n",
    "    if train_accuracy > best_train_accuracy:\n",
    "        best_train_accuracy = train_accuracy\n",
    "        best_train_accuracy_epoch = epoch + 1\n",
    "    if epoch_loss < lowest_train_loss:\n",
    "        lowest_train_loss = epoch_loss\n",
    "        lowest_train_loss_epoch = epoch + 1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# 绘制损失和准确率图\n",
    "epochs = range(1, num_epochs + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_losses, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_losses, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_accuracies, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracies, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Training Accuracy: 0.7208 at epoch 10\n",
      "Lowest Training Loss: 0.9027 at epoch 10\n",
      "Best Validation Accuracy: 0.1154 at epoch 8\n",
      "Lowest Validation Loss: 0.8772 at epoch 10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f'Best Training Accuracy: {best_train_accuracy:.4f} at epoch {best_train_accuracy_epoch}')\n",
    "print(f'Lowest Training Loss: {lowest_train_loss:.4f} at epoch {lowest_train_loss_epoch}')\n",
    "print(f'Best Validation Accuracy: {best_val_accuracy:.4f} at epoch {best_val_accuracy_epoch}')\n",
    "print(f'Lowest Validation Loss: {lowest_val_loss:.4f} at epoch {lowest_val_loss_epoch}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Training Accuracy: 0.7160 at epoch 10\n",
    "Lowest Training Loss: 0.9155 at epoch 10\n",
    "Best Validation Accuracy: 0.1168 at epoch 7\n",
    "Lowest Validation Loss: 0.8112 at epoch 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continue\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def threeSumClosest(nums, target):\n",
    "    \"\"\"\n",
    "    :type nums: List[int]\n",
    "    :type target: int\n",
    "    :rtype: int\n",
    "    [-4,-1,1,2]\n",
    "    \"\"\"\n",
    "    nums.sort()\n",
    "    ans = nums[0] + nums[1] + nums[2]\n",
    "    n = len(nums)\n",
    "    for i in range(n-2):\n",
    "        if i > 0 and nums[i] == nums[i-1]:\n",
    "            print(\"continue\")\n",
    "            continue;\n",
    "        l = i+1\n",
    "        r = n-1\n",
    "        x = nums[i]\n",
    "        while l < r:\n",
    "            y = nums[l]\n",
    "            z = nums[r]\n",
    "            s = x+y+z\n",
    "\n",
    "            if abs(ans-target) > abs(s-target):\n",
    "                ans = s\n",
    "            if s>target:\n",
    "                r -= 1\n",
    "                # while nums[r] == nums[r+1]:\n",
    "                #     r -= 1\n",
    "            elif s < target:\n",
    "                l+=1\n",
    "                # while nums[l] == nums[l-1]:\n",
    "                #     l += 1\n",
    "            else:\n",
    "                return target\n",
    "    return ans\n",
    "                \n",
    "\n",
    "nums = [1,1,1,1]\n",
    "threeSumClosest(nums,0)                \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
