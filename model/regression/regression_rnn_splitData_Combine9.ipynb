{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (39375, 12)\n",
      "y_train shape: (39375,)\n",
      "X_val shape: (4921, 12)\n",
      "y_val shape: (4921,)\n",
      "X_test shape: (4927, 12)\n",
      "y_test shape: (4927,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 初始化空列表用于存储所有数据\n",
    "X_train_list = []\n",
    "y_train_list = []\n",
    "X_val_list = []\n",
    "y_val_list = []\n",
    "X_test_list = []\n",
    "y_test_list = []\n",
    "\n",
    "# 遍历 data_index 从 1 到 9\n",
    "for data_index in range(1, 10):\n",
    "    dataset_path = f\"../../dataset/dataset_0725/p{data_index}\"\n",
    "    os.makedirs(dataset_path, exist_ok=True)\n",
    "\n",
    "    # 加载数据\n",
    "    X_train = np.load(f'{dataset_path}/X_train.npy')\n",
    "    y_train = np.load(f'{dataset_path}/y_train.npy').astype(float).flatten()\n",
    "    X_val = np.load(f'{dataset_path}/X_val.npy')\n",
    "    y_val = np.load(f'{dataset_path}/y_val.npy').astype(float).flatten()\n",
    "    X_test = np.load(f'{dataset_path}/X_test.npy')\n",
    "    y_test = np.load(f'{dataset_path}/y_test.npy').astype(float).flatten()\n",
    "\n",
    "    # 将加载的数据添加到列表中\n",
    "    X_train_list.append(X_train)\n",
    "    y_train_list.append(y_train)\n",
    "    X_val_list.append(X_val)\n",
    "    y_val_list.append(y_val)\n",
    "    X_test_list.append(X_test)\n",
    "    y_test_list.append(y_test)\n",
    "\n",
    "# 将列表中的数据合并到一起\n",
    "X_train = np.concatenate(X_train_list, axis=0)\n",
    "y_train = np.concatenate(y_train_list, axis=0)\n",
    "X_val = np.concatenate(X_val_list, axis=0)\n",
    "y_val = np.concatenate(y_val_list, axis=0)\n",
    "X_test = np.concatenate(X_test_list, axis=0)\n",
    "y_test = np.concatenate(y_test_list, axis=0)\n",
    "\n",
    "# 打印合并后数据的形状\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'y_train shape: {y_train.shape}')\n",
    "print(f'X_val shape: {X_val.shape}')\n",
    "print(f'y_val shape: {y_val.shape}')\n",
    "print(f'X_test shape: {X_test.shape}')\n",
    "print(f'y_test shape: {y_test.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveModel_dir = f'../../savedModel/combined9'\n",
    "os.makedirs(saveModel_dir, exist_ok=True)\n",
    "results_dir = f'../../saveResult/combined9'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "saveplot_dir = f'../../savePlot/combined9'\n",
    "os.makedirs(saveplot_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with lr list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 假设 X_train, y_train, X_val, y_val, X_test, y_test 数据已经存在\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# 将数据转换为 PyTorch 张量\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# 数据归一化\n",
    "mean = X_train_tensor.mean(dim=0, keepdim=True)\n",
    "std = X_train_tensor.std(dim=0, keepdim=True)\n",
    "X_train_tensor = (X_train_tensor - mean) / std\n",
    "X_val_tensor = (X_val_tensor - mean) / std\n",
    "X_test_tensor = (X_test_tensor - mean) / std\n",
    "\n",
    "# 创建数据加载器\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 定义 RNN 回归模型\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# 定义自定义的准确率函数\n",
    "def calculate_custom_accuracy(predictions, targets, tolerance=0.1):\n",
    "    predictions = predictions.detach().cpu().numpy()\n",
    "    targets = targets.detach().cpu().numpy()\n",
    "    correct = np.abs(predictions - targets) < tolerance\n",
    "    accuracy = np.mean(correct)\n",
    "    return accuracy\n",
    "\n",
    "# learning_rates = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6]\n",
    "learning_rates = [ 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "num_epochs = 1000\n",
    "\n",
    "results = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with learning rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning Rate 0.01:   0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning Rate 0.01:  37%|███▋      | 739/2000 [46:41<1:28:55,  4.23s/it]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 定义保存模型的目录\n",
    "\n",
    "\n",
    "\n",
    "# 定义保存模型的函数\n",
    "def save_checkpoint(model, optimizer, epoch, val_accuracy, val_loss, file_path):\n",
    "    \n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'val_accuracy': val_accuracy,\n",
    "        'val_loss': val_loss\n",
    "    }\n",
    "    torch.save(checkpoint, file_path)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for lr in learning_rates:\n",
    "    print(f\"Training with learning rate: {lr}\")\n",
    "    model = RNNModel(input_dim=12, hidden_dim=128, output_dim=1, num_layers=2).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    best_val_accuracy = 0.0\n",
    "    best_val_accuracy_epoch = 0\n",
    "    lowest_val_loss = float('inf')\n",
    "    lowest_val_loss_epoch = 0\n",
    "    best_train_accuracy = 0.0\n",
    "    best_train_accuracy_epoch = 0\n",
    "    lowest_train_loss = float('inf')\n",
    "    lowest_train_loss_epoch = 0\n",
    "    train_output_result = []\n",
    "    train_true_result = []\n",
    "    val_output_result = []\n",
    "    val_true_result = []\n",
    "    for epoch in tqdm(range(num_epochs), desc=f\"Learning Rate {lr}\"):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        all_predictions_train = []\n",
    "        all_labels_train = []\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            inputs = inputs.unsqueeze(1)  # 调整维度为 (batch_size, seq_length, input_dim)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            loss = criterion(outputs, labels.unsqueeze(1))  # 将标签调整为 (batch_size, 1)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            all_predictions_train.append(outputs)\n",
    "            all_labels_train.append(labels.unsqueeze(1))\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        train_losses.append(epoch_loss)\n",
    "        \n",
    "        all_predictions_train = torch.cat(all_predictions_train, dim=0)\n",
    "        all_labels_train = torch.cat(all_labels_train, dim=0)\n",
    "\n",
    "        train_output_result.append(all_predictions_train)\n",
    "        train_true_result.append(all_labels_train)\n",
    "\n",
    "        train_accuracy = calculate_custom_accuracy(all_predictions_train, all_labels_train, tolerance=0.5)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_accuracy = 0.0\n",
    "        all_predictions = []\n",
    "        all_labels = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                inputs = inputs.unsqueeze(1)  # 调整维度为 (batch_size, seq_length, input_dim)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels.unsqueeze(1))  # 将标签调整为 (batch_size, 1)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                \n",
    "                all_predictions.append(outputs)\n",
    "                all_labels.append(labels.unsqueeze(1))\n",
    "        \n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        all_predictions = torch.cat(all_predictions, dim=0)\n",
    "        all_labels = torch.cat(all_labels, dim=0)\n",
    "\n",
    "        val_output_result.append(all_predictions)\n",
    "        val_true_result.append(all_labels)\n",
    "\n",
    "        val_accuracy = calculate_custom_accuracy(all_predictions, all_labels, tolerance=0.5)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        \n",
    "        # 记录最好的准确率和最低的损失\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_val_accuracy_epoch = epoch + 1\n",
    "            # 保存模型\n",
    "            save_checkpoint(model, optimizer, epoch + 1, val_accuracy, val_loss, os.path.join(saveModel_dir, f\"best_val_accuracy_lr_{lr}.pt\"))\n",
    "        \n",
    "        if val_loss < lowest_val_loss:\n",
    "            lowest_val_loss = val_loss\n",
    "            lowest_val_loss_epoch = epoch + 1\n",
    "            # 保存模型\n",
    "            save_checkpoint(model, optimizer, epoch + 1, val_accuracy, val_loss, os.path.join(saveModel_dir, f\"lowest_val_loss_lr_{lr}.pt\"))\n",
    "        \n",
    "        if train_accuracy > best_train_accuracy:\n",
    "            best_train_accuracy = train_accuracy\n",
    "            best_train_accuracy_epoch = epoch + 1\n",
    "            # 保存模型\n",
    "            save_checkpoint(model, optimizer, epoch + 1, train_accuracy, epoch_loss, os.path.join(saveModel_dir, f\"best_train_accuracy_lr_{lr}.pt\"))\n",
    "        \n",
    "        if epoch_loss < lowest_train_loss:\n",
    "            lowest_train_loss = epoch_loss\n",
    "            lowest_train_loss_epoch = epoch + 1\n",
    "            # 保存模型\n",
    "            save_checkpoint(model, optimizer, epoch + 1, train_accuracy, epoch_loss, os.path.join(saveModel_dir, f\"lowest_train_loss_lr_{lr}.pt\"))\n",
    "\n",
    "    results[lr] = {\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'train_accuracies': train_accuracies,\n",
    "        'val_accuracies': val_accuracies,\n",
    "        'best_val_accuracy': best_val_accuracy,\n",
    "        'best_val_accuracy_epoch': best_val_accuracy_epoch,\n",
    "        'lowest_val_loss': lowest_val_loss,\n",
    "        'lowest_val_loss_epoch': lowest_val_loss_epoch,\n",
    "        'best_train_accuracy': best_train_accuracy,\n",
    "        'best_train_accuracy_epoch': best_train_accuracy_epoch,\n",
    "        'lowest_train_loss': lowest_train_loss,\n",
    "        'lowest_train_loss_epoch': lowest_train_loss_epoch,\n",
    "        'train_output_result': train_output_result,\n",
    "        'train_true_result': train_true_result,\n",
    "        'val_output_result': val_output_result,\n",
    "        'val_true_result': val_true_result\n",
    "    }\n",
    "\n",
    "    import os\n",
    "\n",
    "# 创建保存图片的目录\n",
    "\n",
    "\n",
    "# 绘制图表\n",
    "for lr, result in results.items():\n",
    "    epochs = range(1, num_epochs + 1)\n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, result['train_losses'], 'bo-', label='Training loss')\n",
    "    plt.plot(epochs, result['val_losses'], 'b-', label='Validation loss')\n",
    "    plt.title(f'Training and validation loss (lr={lr})')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, result['train_accuracies'], 'bo-', label='Training accuracy')\n",
    "    plt.plot(epochs, result['val_accuracies'], 'b-', label='Validation accuracy')\n",
    "    plt.title(f'Training and validation accuracy (lr={lr})')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 保存图片\n",
    "    plot_filename = os.path.join(saveplot_dir, f'training_validation_lr_{lr}.png')\n",
    "    plt.savefig(plot_filename)\n",
    "    \n",
    "    # 显示图片\n",
    "    plt.show()\n",
    "# 定义保存文件的路径\n",
    "results_file = 'training_results.txt'\n",
    "\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "# 打开文件写入模式\n",
    "with open(f'{results_dir}/{results_file}', 'w') as f:\n",
    "    for lr, result in results.items():\n",
    "        f.write(f\"Learning rate: {lr}\\n\")\n",
    "        f.write(f\"Best Validation Accuracy: {result['best_val_accuracy']:.4f} at epoch {result['best_val_accuracy_epoch']}\\n\")\n",
    "        f.write(f\"Lowest Validation Loss: {result['lowest_val_loss']:.4f} at epoch {result['lowest_val_loss_epoch']}\\n\")\n",
    "        f.write(f\"Best Training Accuracy: {result['best_train_accuracy']:.4f} at epoch {result['best_train_accuracy_epoch']}\\n\")\n",
    "        f.write(f\"Lowest Training Loss: {result['lowest_train_loss']:.4f} at epoch {result['lowest_train_loss_epoch']}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "print(f\"Results saved to {results_dir}/{results_file}\")\n",
    "\n",
    "for lr, result in results.items():\n",
    "    print(f\"Learning rate: {lr}\")\n",
    "    print(f\"Best Validation Accuracy: {result['best_val_accuracy']:.4f} at epoch {result['best_val_accuracy_epoch']}\")\n",
    "    print(f\"Lowest Validation Loss: {result['lowest_val_loss']:.4f} at epoch {result['lowest_val_loss_epoch']}\")\n",
    "    print(f\"Best Training Accuracy: {result['best_train_accuracy']:.4f} at epoch {result['best_train_accuracy_epoch']}\")\n",
    "    print(f\"Lowest Training Loss: {result['lowest_train_loss']:.4f} at epoch {result['lowest_train_loss_epoch']}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
